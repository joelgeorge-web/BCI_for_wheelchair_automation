{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf68531f",
   "metadata": {},
   "source": [
    "# 5 mins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4d9fd7d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully converted C:\\Users\\HP\\Downloads\\jg_rest_eye_right_600.wav to E:\\Joel\\Bioamp_Data\\Data\\George\\jg_rest_eye_right_600.csv\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from scipy.io import wavfile\n",
    "import pandas as pd\n",
    "\n",
    "def convert_wav_to_csv(input_path, output_folder):\n",
    "    # Check if the input file has a '.wav' extension\n",
    "    if not input_path.lower().endswith('.wav'):\n",
    "        print('WARNING!! Input File format should be *.wav')\n",
    "        return\n",
    "\n",
    "   \n",
    "\n",
    "    # Read the WAV file\n",
    "    sample_rate, data = wavfile.read(input_path)\n",
    "\n",
    "    # Create a DataFrame from the WAV data\n",
    "    wav_data_df = pd.DataFrame(data)\n",
    "\n",
    "    # Write the DataFrame to a CSV file\n",
    "    wav_data_df.to_csv(output_folder, mode='w', index=False)\n",
    "\n",
    "    print(f'Successfully converted {input_path} to {output_folder}')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Specify the input filename and output folder\n",
    "    input_filename =r\"C:\\Users\\HP\\Downloads\\jg_rest_eye_right_600.wav\"\n",
    "    output_folder = r\"E:\\Joel\\Bioamp_Data\\Data\\George\\jg_rest_eye_right_600.csv\"\n",
    "\n",
    "    # Perform the WAV to CSV conversion\n",
    "    convert_wav_to_csv(input_filename, output_folder)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a136808d",
   "metadata": {},
   "source": [
    "# 3 mins "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5caf32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, os.path\n",
    "from scipy.io import wavfile\n",
    "import pandas as pd\n",
    "\n",
    "input_filename = r\"C:\\Users\\HP\\Documents\\BYB\\Jose_Jaw_Rest_5mins\"\n",
    "if input_filename[-3:] != 'wav':\n",
    "    print('WARNING!! Input File format should be *.wav')\n",
    "    sys.exit()\n",
    "\n",
    "sample_rate, data = wavfile.read(str('./wavfile/' + input_filename))\n",
    "print('Load is Done! \\n')\n",
    "wavData = pd.DataFrame(data)\n",
    "print('Multi channel .wav file\\n')\n",
    "print('number of channel : ' + str(len(wavData.columns)))\n",
    "\n",
    "wavData.to_csv(input_filename[:-4] + \"Sandra_30_jaw.csv\", mode='w')\n",
    "print('Save is done ' + str(input_filename[:-4]) + 'Sandra_30_jaw.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef35242",
   "metadata": {},
   "source": [
    "# Transposing CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ccede981",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "15a8b9a7",
   "metadata": {},
   "source": [
    "# 50000 for 5 secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6514fb37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing completed.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "i=0\n",
    "\n",
    "def process_chunk(chunk,inp):\n",
    "   \n",
    "    values_chunk = chunk.values.flatten().tolist()\n",
    "    processed_rows = values_chunk + [inp]\n",
    "    \n",
    "    \n",
    "    return processed_rows\n",
    "\n",
    "chunk_size = 50000\n",
    "input_file=r\"D:\\Joel\\Bioamp_Data\\Data\\Jaw_Clench\\Alpha-beta\\Jose_Jaw_Blink_5mins.csv\"\n",
    "output_file = r\"D:\\Joel\\Bioamp_Data\\Data\\Jaw_Clench\\Alpha-beta\\Jose_Jaw_Blink_5mins_transposed.csv\"\n",
    "target_values = [\"JAW\",\"BLINK\"]\n",
    "\n",
    "for chunk in pd.read_csv(input_file, chunksize=chunk_size, header=None,nrows=3000000):\n",
    "    if(i>1):\n",
    "        i=0\n",
    "    inp=target_values[i]\n",
    "    processed_row = process_chunk(chunk,inp)\n",
    "    i=i+1\n",
    "    pd.DataFrame([processed_row]).to_csv(output_file, mode='a', header=False, index=False)\n",
    "\n",
    "print(\"Processing completed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90dab995",
   "metadata": {},
   "source": [
    "# 25000 for 2.5 secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9d8470c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Read the CSV file\n",
    "input_csv_path =r\"E:\\Joel\\Bioamp_Data\\Data\\George\\jg_rest_eye_right_600.csv\"\n",
    "output_csv_path = r\"E:\\Joel\\Bioamp_Data\\Data\\George\\Labelled_jg_rest_eye_right_600.csv\"\n",
    "\n",
    "# Set the chunk size\n",
    "chunk_size = 25000\n",
    "\n",
    "# Initialize a list to store transposed chunks and target values\n",
    "transposed_chunks = []\n",
    "\n",
    "# Define the target values pattern\n",
    "target_values_pattern = [\"REST\", \"RIGHT\"]\n",
    "\n",
    "# Iterate over chunks of the input CSV file\n",
    "for i, chunk in enumerate(pd.read_csv(input_csv_path, chunksize=chunk_size, header=None, nrows=600000)):\n",
    "    # Transpose the chunk\n",
    "    transposed_chunk = chunk.T.values.flatten()\n",
    "\n",
    "    # Calculate the number of times the pattern needs to be repeated\n",
    "    pattern_repeats = len(transposed_chunk) // len(target_values_pattern)\n",
    "\n",
    "    # Get the corresponding target values based on the pattern\n",
    "    target_values = np.tile(target_values_pattern, pattern_repeats)[:len(transposed_chunk)]\n",
    "\n",
    "    # Add the target values to the transposed chunk\n",
    "    transposed_chunk_with_targets = np.column_stack((transposed_chunk, target_values))\n",
    "\n",
    "    # Append the transposed chunk with target values to the list\n",
    "    transposed_chunks.append(transposed_chunk_with_targets)\n",
    "\n",
    "# Create a DataFrame from the transposed chunks\n",
    "transposed_df = pd.DataFrame(np.concatenate(transposed_chunks, axis=0))\n",
    "\n",
    "# Write the transposed data with target values to a new CSV file\n",
    "transposed_df.to_csv(output_csv_path, index=False, header=False)\n",
    "print(\"Success\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ec3690",
   "metadata": {},
   "source": [
    "# 20000 for 2 Secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a3edb5c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing completed.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "i=0\n",
    "\n",
    "def process_chunk(chunk,inp):\n",
    "   \n",
    "    values_chunk = chunk.values.flatten().tolist()\n",
    "    processed_rows = values_chunk + [inp]\n",
    "    \n",
    "    \n",
    "    return processed_rows\n",
    "\n",
    "chunk_size = 20000\n",
    "input_file=r\"D:\\Joel\\Bioamp_Data\\Data\\Jaw_Clench\\23_Dec\\Jose_Jaw_Blink_5mins_10secs_6.csv\"\n",
    "output_file = r\"D:\\Joel\\Bioamp_Data\\Data\\Jaw_Clench\\23_Dec\\Transposed\\Jose_Jaw_Blink_5mins_10secs_6_transposed.csv\"\n",
    "target_values = [\"JAW\", \"JAW\", \"JAW\", \"JAW\", \"JAW\", \"BLINK\", \"BLINK\", \"BLINK\", \"BLINK\", \"BLINK\"]\n",
    "\n",
    "for chunk in pd.read_csv(input_file, chunksize=chunk_size, header=None,nrows=3000000):\n",
    "    if(i>9):\n",
    "        i=0\n",
    "    inp=target_values[i]\n",
    "    processed_row = process_chunk(chunk,inp)\n",
    "    i=i+1\n",
    "    pd.DataFrame([processed_row]).to_csv(output_file, mode='a', header=False, index=False)\n",
    "\n",
    "print(\"Processing completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f4649197",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       0     1\n",
      "0      0  REST\n",
      "1    607  LEFT\n",
      "2    623  REST\n",
      "3    638  LEFT\n",
      "4    654  REST\n",
      "5    671  LEFT\n",
      "6    688  REST\n",
      "7    705  LEFT\n",
      "8    722  REST\n",
      "9    741  LEFT\n",
      "10   759  REST\n",
      "11   778  LEFT\n",
      "12   797  REST\n",
      "13   816  LEFT\n",
      "14   836  REST\n",
      "15   856  LEFT\n",
      "16   878  REST\n",
      "17   899  LEFT\n",
      "18   920  REST\n",
      "19   942  LEFT\n",
      "20   964  REST\n",
      "21   986  LEFT\n",
      "22  1009  REST\n",
      "23  1033  LEFT\n",
      "24  1057  REST\n",
      "\n",
      " \n",
      "(600000, 2)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv(r\"E:\\Joel\\Bioamp_Data\\Data\\George\\labelled_New_Test_2.5_Rest_Left_1min.csv\",header=None)\n",
    "print(df.head(25))\n",
    "print(\"\\n \")\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "544ce787",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_3804\\244843867.py:16: DtypeWarning: Columns (7393) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path,nrows=60)\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_3804\\244843867.py:17: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  merged_df = merged_df.append(df, ignore_index=True)\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_3804\\244843867.py:16: DtypeWarning: Columns (14417) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path,nrows=60)\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_3804\\244843867.py:17: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  merged_df = merged_df.append(df, ignore_index=True)\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_3804\\244843867.py:16: DtypeWarning: Columns (28705) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path,nrows=60)\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_3804\\244843867.py:17: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  merged_df = merged_df.append(df, ignore_index=True)\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_3804\\244843867.py:16: DtypeWarning: Columns (9153) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path,nrows=60)\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_3804\\244843867.py:17: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  merged_df = merged_df.append(df, ignore_index=True)\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_3804\\244843867.py:16: DtypeWarning: Columns (20177) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path,nrows=60)\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_3804\\244843867.py:17: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  merged_df = merged_df.append(df, ignore_index=True)\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_3804\\244843867.py:16: DtypeWarning: Columns (9729) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path,nrows=60)\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_3804\\244843867.py:17: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  merged_df = merged_df.append(df, ignore_index=True)\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_3804\\244843867.py:16: DtypeWarning: Columns (18993) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path,nrows=60)\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_3804\\244843867.py:17: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  merged_df = merged_df.append(df, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data from 7 CSV files has been merged and saved to D:\\Joel\\Bioamp_Data\\Data\\Jaw_Clench\\Alpha-beta\\Jose_Jaw_Blink_Rest_Merged\\Jose_Jaw_Blink_Rest_Merged_5000.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Replace the directory path with the path to your CSV files\n",
    "directory_path = r'D:\\Joel\\Bioamp_Data\\Data\\Jaw_Clench\\Alpha-beta\\Transposed'\n",
    "\n",
    "# List all CSV files in the directory\n",
    "csv_files = [file for file in os.listdir(directory_path) if file.endswith('.csv')]\n",
    "\n",
    "# Initialize an empty DataFrame to store the merged data\n",
    "merged_df = pd.DataFrame()\n",
    "\n",
    "# Loop through each CSV file and append its content to the merged DataFrame\n",
    "for file in csv_files:\n",
    "    file_path = os.path.join(directory_path, file)\n",
    "    df = pd.read_csv(file_path,nrows=60)\n",
    "    merged_df = merged_df.append(df, ignore_index=True)\n",
    "\n",
    "# Specify the path for the output merged CSV file\n",
    "output_file_path = r\"D:\\Joel\\Bioamp_Data\\Data\\Jaw_Clench\\Alpha-beta\\Jose_Jaw_Blink_Rest_Merged\\Jose_Jaw_Blink_Rest_Merged_5000.csv\"\n",
    "\n",
    "# Save the merged DataFrame to a new CSV file\n",
    "merged_df.to_csv(output_file_path, index=False)\n",
    "\n",
    "print(f'Data from {len(csv_files)} CSV files has been merged and saved to {output_file_path}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "af663078",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       JAW\n",
       "1     BLINK\n",
       "2       JAW\n",
       "3     BLINK\n",
       "4       JAW\n",
       "      ...  \n",
       "56      JAW\n",
       "57    BLINK\n",
       "58      JAW\n",
       "59    BLINK\n",
       "60      NaN\n",
       "Name: 50000, Length: 61, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "transposed_data = pd.read_csv(r\"D:\\Joel\\Bioamp_Data\\Data\\Jaw_Clench\\Alpha-beta\\Jose_Jaw_Blink_5mins_transposed.csv\", header=None)\n",
    "\n",
    "\n",
    "# Get the last column\n",
    "last_column = df.iloc[:, -1]\n",
    "last_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "d085f8b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'REST', nan}"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(last_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "efdc350a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(469, 88469)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transposed_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6ceeae42",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12424\\1977124213.py:9: DtypeWarning: Columns (20177) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path, header=None)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "File: D:\\Joel\\Bioamp_Data\\Data\\Jaw_Clench\\Alpha-beta\\Jose_Jaw_Blink_5mins_transposed_50000.csv\n",
      "Shape (rows, columns): (61, 50001)\n",
      "Last column:\n",
      "0       JAW\n",
      "1     BLINK\n",
      "2       JAW\n",
      "3     BLINK\n",
      "4       JAW\n",
      "      ...  \n",
      "56      JAW\n",
      "57    BLINK\n",
      "58      JAW\n",
      "59    BLINK\n",
      "60      NaN\n",
      "Name: 50000, Length: 61, dtype: object\n",
      "\n",
      "Unique values in the last column:\n",
      "['JAW' 'BLINK' nan]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_paths = [\n",
    "   \"D:\\Joel\\Bioamp_Data\\Data\\Jaw_Clench\\Alpha-beta\\Jose_Jaw_Blink_5mins_transposed_50000.csv\"\n",
    "]\n",
    "\n",
    "for file_path in file_paths:\n",
    "    try:\n",
    "        df = pd.read_csv(file_path, header=None)\n",
    "        print(f\"\\nFile: {file_path}\")\n",
    "        print(f\"Shape (rows, columns): {df.shape}\")\n",
    "        print(f\"Last column:\\n{df.iloc[:, -1]}\\n\")\n",
    "        # Get the unique values in the last column\n",
    "        unique_values = df.iloc[:, -1].unique()\n",
    "        \n",
    "        print(f\"Unique values in the last column:\\n{unique_values}\\n\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {file_path}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d1495d6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged DataFrame shape: (900, 20001)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def merge_files_in_folder(folder_path, output_file_path):\n",
    "    file_paths = [os.path.join(folder_path, file) for file in os.listdir(folder_path) if file.endswith('.csv')]\n",
    "\n",
    "    # Initialize an empty list to store DataFrames\n",
    "    dfs = []\n",
    "\n",
    "    for file_path in file_paths:\n",
    "        try:\n",
    "            # Read each file as a DataFrame without headers\n",
    "            df = pd.read_csv(file_path, header=None)\n",
    "\n",
    "            # Drop rows with NaN values\n",
    "            df = df.dropna()\n",
    "\n",
    "            dfs.append(df)\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading {file_path}: {e}\")\n",
    "\n",
    "    if dfs:\n",
    "        # Concatenate DataFrames along the rows (axis=0)\n",
    "        merged_df = pd.concat(dfs, axis=0, ignore_index=True)\n",
    "\n",
    "        # Write the merged DataFrame to a new CSV file\n",
    "        merged_df.to_csv(output_file_path, index=False, header=False)\n",
    "        print(f\"Merged DataFrame shape: {merged_df.shape}\")\n",
    "    else:\n",
    "        print(\"No valid DataFrames to merge.\")\n",
    "\n",
    "# Example usage\n",
    "folder_path = r\"D:\\Joel\\Bioamp_Data\\Data\\Jaw_Clench\\23_Dec\\Transposed\"\n",
    "output_file_path = r\"D:\\Joel\\Bioamp_Data\\Data\\Jaw_Clench\\23_Dec\\Merged\\merged_output.csv\"\n",
    "\n",
    "merge_files_in_folder(folder_path, output_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d29a4bfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Read the CSV file\n",
    "input_csv_path =r\"E:\\Joel\\Bioamp_Data\\Data\\George\\jg_rest_eye_right_600.csv\"\n",
    "output_csv_path = r\"E:\\Joel\\Bioamp_Data\\Data\\George\\Labelled_jg_rest_eye_right_600.csv\"\n",
    "\n",
    "# Set the chunk size\n",
    "chunk_size = 25000\n",
    "\n",
    "# Initialize an empty list to store transposed chunks\n",
    "transposed_chunks = []\n",
    "\n",
    "# Define the target values pattern\n",
    "target_values_pattern = [ \"REST\",\"RIGHT\"]\n",
    "c=0\n",
    "# Read and process chunks of the input CSV file\n",
    "for chunk in pd.read_csv(input_csv_path, chunksize=chunk_size, header=None, nrows=6000000):\n",
    "    # Transpose the chunk\n",
    "    transposed_chunk = chunk.T.values.flatten()\n",
    "    if c>1:\n",
    "        c=0\n",
    "    # Append the target values to the transposed chunk\n",
    "    transposed_chunk = np.append(transposed_chunk, target_values_pattern[c])\n",
    "    # Append the transposed chunk to the list\n",
    "    transposed_chunks.append(transposed_chunk)\n",
    "    c+=1\n",
    "# Create a DataFrame from the transposed chunks\n",
    "transposed_df = pd.DataFrame(transposed_chunks)\n",
    "\n",
    "# Write the transposed data with target values to a new CSV file\n",
    "transposed_df.to_csv(output_csv_path, index=False, header=False)\n",
    "print(\"Success\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64f2c972",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(600000, 1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data=pd.read_csv(r\"E:\\Joel\\Bioamp_Data\\Data\\George\\jg_rest_eye_right_600.csv\",header=None,nrows=600000)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fa752326",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(240, 25000)\n",
      "0         int64\n",
      "1         int64\n",
      "2         int64\n",
      "3         int64\n",
      "4         int64\n",
      "          ...  \n",
      "24996     int64\n",
      "24997     int64\n",
      "24998     int64\n",
      "24999     int64\n",
      "25000    object\n",
      "Length: 25001, dtype: object\n",
      "Features calculated and appended to E:\\Joel\\Bioamp_Data\\Data\\George\\CHeck_test.csv.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import kurtosis\n",
    "import csv\n",
    "# Read EEG data from CSV file\n",
    "input_file = r\"E:\\Joel\\Bioamp_Data\\Data\\George\\2.5secs_Labelled_JG_Rest_Left_10mins.csv\"\n",
    "output_file = r\"E:\\Joel\\Bioamp_Data\\Data\\George\\CHeck_test.csv\"  # Replace with the desired output file path\n",
    "data = pd.read_csv(input_file, header=None)\n",
    "\n",
    "# Extract EEG signals (all columns except the last one)\n",
    "eeg_data = data.iloc[:, :-1].values\n",
    "print(eeg_data.shape)\n",
    "print(data.dtypes)\n",
    "# Function to calculate features for each row\n",
    "def calculate_row_features(row):\n",
    "    \n",
    "    return {\n",
    "        'Max': np.max(row),\n",
    "        'Min': np.min(row),\n",
    "        'Mean': np.mean(row),\n",
    "        'Variance': np.var(row),\n",
    "        'Kurtosis': kurtosis(row),\n",
    "    }\n",
    "\n",
    "# Append features and target label to the output file\n",
    "with open(output_file, 'a', newline='') as csvfile:\n",
    "    # Create a CSV writer\n",
    "    csv_writer = csv.writer(csvfile)\n",
    "\n",
    "    # Iterate through each row\n",
    "    for idx, row in enumerate(eeg_data):\n",
    "        # Calculate features for the row\n",
    "        row_features = calculate_row_features(row)\n",
    "        \n",
    "        # Append target label to the row features\n",
    "        row_features['Target'] = data.iloc[idx, -1]\n",
    "        \n",
    "        # Write the row to the output CSV file\n",
    "        csv_writer.writerow(row_features.values())\n",
    "\n",
    "print(f\"Features calculated and appended to {output_file}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53cddbfa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
