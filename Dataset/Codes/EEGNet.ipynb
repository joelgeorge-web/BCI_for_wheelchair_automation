{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02fd1006",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n",
    "# initialize the model\n",
    "model = Sequential()\n",
    "\n",
    "# add first convolutional layer\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', input_shape=(64, 64, 3)))\n",
    "\n",
    "# add second convolutional layer\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "\n",
    "# add max pooling layer\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# add third convolutional layer\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "\n",
    "# add fourth convolutional layer\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "\n",
    "# add fifth convolutional layer\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "\n",
    "# add flatten layer\n",
    "model.add(Flatten())\n",
    "\n",
    "# add first dense layer\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "\n",
    "# add dropout layer for regularization\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# add second dense layer\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e356f40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382f4d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming you have a CSV file with a header, e.g., ['feature1', 'feature2', ..., 'target1']\n",
    "\n",
    "# Read the CSV file into a pandas DataFrame\n",
    "data = pd.read_csv('path_to_your_csv_file.csv')\n",
    "\n",
    "# Separate the features and targets\n",
    "features = data.iloc[:, :-1]\n",
    "targets = data.iloc[:, -1]\n",
    "\n",
    "# Create the training and testing sets\n",
    "# Here, we are assuming you have 80% of your data for training and 20% for testing\n",
    "train_features = features.iloc[:int(0.8*len(features))]\n",
    "test_features = features.iloc[int(0.8*len(features)):]\n",
    "\n",
    "train_targets = targets.iloc[:int(0.8*len(targets))]\n",
    "test_targets = targets.iloc[int(0.8*len(targets)):]\n",
    "\n",
    "# Reshape your target variable to match the dimensions of your input layer\n",
    "train_targets = train_targets.values.reshape(-1, 641, 1)\n",
    "test_targets = test_targets.values.reshape(-1, 641, 1)\n",
    "\n",
    "# Now, you can use these training and testing sets to train your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4380b9a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling layer \"depthwise_conv2d\" (type DepthwiseConv2D).\n\nNegative dimension size caused by subtracting 1 from 0 for '{{node depthwise_conv2d/depthwise}} = DepthwiseConv2dNative[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 1, 1]](Placeholder, depthwise_conv2d/depthwise/ReadVariableOp)' with input shapes: [?,4885,0,8], [4885,1,8,2].\n\nCall arguments received by layer \"depthwise_conv2d\" (type DepthwiseConv2D):\n  â€¢ inputs=tf.Tensor(shape=(None, 4885, 0, 8), dtype=float32)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 42\u001b[0m\n\u001b[0;32m     40\u001b[0m model\u001b[38;5;241m.\u001b[39madd(layers\u001b[38;5;241m.\u001b[39mConv2D(\u001b[38;5;241m8\u001b[39m, (\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m64\u001b[39m), input_shape\u001b[38;5;241m=\u001b[39m(epochs\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], epochs\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m], \u001b[38;5;241m1\u001b[39m), padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msame\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m     41\u001b[0m model\u001b[38;5;241m.\u001b[39madd(layers\u001b[38;5;241m.\u001b[39mBatchNormalization())\n\u001b[1;32m---> 42\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlayers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDepthwiseConv2D\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkernel_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdepth_multiplier\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdepthwise_initializer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhe_normal\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_bias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvalid\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     43\u001b[0m model\u001b[38;5;241m.\u001b[39madd(layers\u001b[38;5;241m.\u001b[39mBatchNormalization())\n\u001b[0;32m     44\u001b[0m model\u001b[38;5;241m.\u001b[39madd(layers\u001b[38;5;241m.\u001b[39mDepthwiseConv2D(kernel_size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m16\u001b[39m), depth_multiplier\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, depthwise_initializer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhe_normal\u001b[39m\u001b[38;5;124m'\u001b[39m, use_bias\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msame\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\trackable\\base.py:204\u001b[0m, in \u001b[0;36mno_automatic_dependency_tracking.<locals>._method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    202\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_self_setattr_tracking \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    203\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 204\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    206\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_self_setattr_tracking \u001b[38;5;241m=\u001b[39m previous_value  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:6448\u001b[0m, in \u001b[0;36mdepthwise_conv2d\u001b[1;34m(x, depthwise_kernel, strides, padding, data_format, dilation_rate)\u001b[0m\n\u001b[0;32m   6445\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6446\u001b[0m     strides \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m+\u001b[39m strides\n\u001b[1;32m-> 6448\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdepthwise_conv2d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   6449\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   6450\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdepthwise_kernel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   6451\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstrides\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstrides\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   6452\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   6453\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdilations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdilation_rate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   6454\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtf_data_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   6455\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m data_format \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchannels_first\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m tf_data_format \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNHWC\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   6457\u001b[0m     x \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mcompat\u001b[38;5;241m.\u001b[39mv1\u001b[38;5;241m.\u001b[39mtranspose(x, (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m))  \u001b[38;5;66;03m# NHWC -> NCHW\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: Exception encountered when calling layer \"depthwise_conv2d\" (type DepthwiseConv2D).\n\nNegative dimension size caused by subtracting 1 from 0 for '{{node depthwise_conv2d/depthwise}} = DepthwiseConv2dNative[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 1, 1]](Placeholder, depthwise_conv2d/depthwise/ReadVariableOp)' with input shapes: [?,4885,0,8], [4885,1,8,2].\n\nCall arguments received by layer \"depthwise_conv2d\" (type DepthwiseConv2D):\n  â€¢ inputs=tf.Tensor(shape=(None, 4885, 0, 8), dtype=float32)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Load EEG data from CSV\n",
    "eeg_data = pd.read_csv(r\"C:\\Users\\HP\\Desktop\\Dataset\\Model_Input_2sec\\LR_2sec.csv\")\n",
    "\n",
    "# Define the number of rows in each epoch (4 seconds)\n",
    "epoch_length = 321\n",
    "\n",
    "# Initialize lists to store epochs and labels\n",
    "epochs = []\n",
    "labels = []\n",
    "\n",
    "# Extract EEG data and labels\n",
    "for i in range(0, len(eeg_data), epoch_length):\n",
    "    epoch = eeg_data.iloc[i:i + epoch_length]\n",
    "    if len(epoch) == epoch_length:\n",
    "        eeg_epoch = epoch.iloc[:, 1:-1].values  # Assuming EEG channels are from column 1 to the second-to-last column\n",
    "        label = epoch.iloc[0, -1]  # Assuming the target is in the last column\n",
    "        epochs.append(eeg_epoch)\n",
    "        labels.append(label)\n",
    "\n",
    "# Convert to NumPy arrays\n",
    "epochs = np.array(epochs)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Perform label encoding for multi-class classification\n",
    "label_encoder = LabelEncoder()\n",
    "labels_encoded = label_encoder.fit_transform(labels)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(epochs, labels_encoded, test_size=0.3, random_state=42)\n",
    "\n",
    "# Define EEGNet architecture\n",
    "model = keras.Sequential()\n",
    "model.add(layers.Conv2D(8, (1, 64), input_shape=(epochs.shape[1], epochs.shape[2], 1), padding='same'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.DepthwiseConv2D(kernel_size=(epochs.shape[1], 1), depth_multiplier=2, depthwise_initializer='he_normal', use_bias=False, padding='valid'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.DepthwiseConv2D(kernel_size=(1, 16), depth_multiplier=2, depthwise_initializer='he_normal', use_bias=False, padding='same'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Activation('elu'))\n",
    "model.add(layers.AveragePooling2D(pool_size=(1, 4)))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.SeparableConv2D(16, (1, 16), activation='elu', depthwise_initializer='he_normal', use_bias=False, padding='same'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.SeparableConv2D(16, (1, 16), activation='elu', depthwise_initializer='he_normal', use_bias=False, padding='same'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.AveragePooling2D(pool_size=(1, 4)))  # Adjust the pool_size as needed\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(3, activation='softmax'))  # 3 classes (Left, Right, Rest)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Reshape data to match the input shape\n",
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], X_train.shape[2], 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], X_test.shape[2], 1)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=15, batch_size=32, validation_split=0.1)\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Loss: {loss}, Test Accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a14b9e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
